# app.py
import os
import pickle
import requests
from flask import Flask, request, jsonify
from flask_cors import CORS # Necesario si Node.js y Python corren en diferentes puertos

app = Flask(__name__)
# Permite peticiones desde el frontend (Node.js/Flutter)
# En un entorno de producci√≥n (Railway), se recomienda especificar los or√≠genes
CORS(app) 

# Variables globales para el modelo y el vectorizador
modelo_clasificacion = None
vectorizador_texto = None

# Configuraci√≥n del modelo directions
BASE_DIR = os.path.abspath(os.path.dirname(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "Vak_model.pkl")
VECTOR_PATH = os.path.join(BASE_DIR, "Tfidf_vectorizer.pkl")

# URL de los modelos en Drive (si es necesario descargarlos)
VECTOR_URL = "https://drive.google.com/file/d/1nmHXfLcbFi0yNW_5po7rkhVYlLxYZvD0/view?usp=drive_link"
MODEL_URL = "https://drive.google.com/file/d/15QD4nHZQRb0LwrOZid9I9Kx89a-NZ8IM/view?usp=drive_link"

def download_file(url, path):
    """Descarga un archivo desde una URL si no existe localmente."""
    if not os.path.exists(path):
        print(f"üåç Descargando {os.path.basename(path)} desde {url}...")
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status() # Lanza error para c√≥digos HTTP malos
            with open(path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            print(f"‚úÖ Descarga completa de {os.path.basename(path)}.")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Error al descargar {os.path.basename(path)}: {e}")
            exit(1)
    else:
        print(f"‚òëÔ∏è {os.path.basename(path)} ya existe localmente, omitiendo descarga.")

# --- Funci√≥n para cargar los archivos .pkl ---
def cargar_modelo():
    """Carga el modelo y el vectorizador desde los archivos .pkl."""
    global modelo_clasificacion, vectorizador_texto
    
    # Intenta descargar los archivos primero
    download_file(MODEL_URL, MODEL_PATH)
    download_file(VECTOR_URL, VECTOR_PATH)

    try:
        # Cargar el modelo (Ej: Naive Bayes, SVM, etc.)
        with open(MODEL_PATH, 'rb') as f:
            modelo_clasificacion = pickle.load(f)
        
        # Cargar el vectorizador (Ej: TfidfVectorizer, CountVectorizer)
        with open(VECTOR_PATH, 'rb') as f:
            vectorizador_texto = pickle.load(f)
        
        print("‚úÖ Modelos .pkl cargados correctamente en memoria.")
    except FileNotFoundError:
        print("‚ùå Error: No se encontraron 'modelo.pkl' o 'vectorizador.pkl'.")
        # Esto deber√≠a detener el servicio si los archivos son cr√≠ticos
        exit(1)
    except Exception as e:
        print(f"‚ùå Error al cargar los modelos: {e}")
        exit(1)

# Llama a la funci√≥n de carga inmediatamente despu√©s de definirla
# Esto se ejecutar√° tanto localmente como en Gunicorn/Railway
cargar_modelo() # <-- Mover esta llamada aqu√≠

# --- Endpoint de Clasificaci√≥n ---
@app.route('/classify', methods=['POST'])
def classify_text():
    """
    Recibe un texto en ingl√©s (pre-traducido por Node.js) y retorna la clasificaci√≥n VAK.
    """
    if not request.json or 'text' not in request.json:
        return jsonify({
            'error': 'Falta el campo "text" en la solicitud JSON.'
        }), 400

    texto_input = request.json['text']
    
    # 1. Verificar si el texto es v√°lido
    if not isinstance(texto_input, str) or len(texto_input.strip()) == 0:
        return jsonify({
            'error': 'El campo "text" debe ser una cadena no vac√≠a.'
        }), 400

    try:
        # 2. Vectorizar el texto de entrada
        # IMPORTANTE: El texto debe estar en el formato (ej. limpio y en ingl√©s)
        # esperado por el vectorizador entrenado.
        texto_vectorizado = vectorizador_texto.transform([texto_input])
        
        # 3. Predecir la clasificaci√≥n
        prediccion = modelo_clasificacion.predict(texto_vectorizado)
        
        # 4. CORRECCI√ìN CR√çTICA: Extraer el string del array de NumPy
        # Ejemplo: array(['Auditory'], dtype=object) -> 'Auditory'
        if prediccion.size > 0:
            # Extraer el primer (y √∫nico) elemento y convertirlo a string simple
            estilo_clasificado = str(prediccion[0])
        else:
            # En caso de que la predicci√≥n falle (array vac√≠o)
            estilo_clasificado = None 

        # 5. Devolver el resultado
        # Si prediccion.size > 0, estilo_clasificado ser√° 'Auditory' (string).
        # Si falla, ser√° None (lo que Node.js deber√° manejar como fallo).
        return jsonify({
            'estilo': estilo_clasificado, # 'V', 'A', o 'K'
            'texto_recibido': texto_input
        })

    except Exception as e:
        # En caso de un error inesperado durante la predicci√≥n
        return jsonify({
            'error': f'Error interno durante la clasificaci√≥n: {e}'
        }), 500

# --- Punto de inicio ---
if __name__ == '__main__':
    # Carga los modelos ANTES de iniciar el servidor
    cargar_modelo()
    
    # Aseg√∫rate de usar el puerto que requiere Railway o tu entorno local (ej. 5000)
    # En Railway, el puerto se puede definir con la variable de entorno PORT
    # Para desarrollo local: app.run(debug=True, port=5000)
    app.run(host='0.0.0.0', port=5000)